{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "8b633014-bbed-4230-b9cc-2976f329e26b",
            "metadata": {},
            "source": [
                "# Text Autocomplete Comparison\n",
                "\n",
                "This notebook compares the performance of transformer-based models for text autocomplete tasks, focusing on Filipino (Tagalog) language processing. We evaluate:\n",
                "- **BaseBERT**: A baseline BERT model for Filipino.\n",
                "- **CGABERT**: An enhanced model with optimized attention mechanisms for Filipino NLP.\n",
                "\n",
                "The notebook fine-tunes the models, evaluates their performance, and saves the results for visualization in a GUI."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8c8006d3-0b9b-44da-9f2d-d6d2652917b1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "%pip install transformers datasets torch evaluate huggingface_hub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1ca5463d-411d-444d-a6b7-bc9a5b5c8ffc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import os\n",
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from transformers import (\n",
                "    BertForMaskedLM,\n",
                "    RobertaForMaskedLM,\n",
                "    AutoTokenizer,\n",
                "    Trainer,\n",
                "    TrainingArguments,\n",
                "    DataCollatorForLanguageModeling\n",
                ")\n",
                "from datasets import load_dataset, Dataset\n",
                "import evaluate\n",
                "from pathlib import Path\n",
                "import time\n",
                "import json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bb63fdc2-5cad-4f50-97f0-0eef5f775dc4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "input_dir = Path('/kaggle/input') if Path('/kaggle/input').exists() else Path('.')\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "003b2689-6133-468e-aea9-df16433e8d3a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load user-specified dataset\n",
                "dataset_path = os.environ.get('DATASET_PATH', '')\n",
                "if dataset_path:\n",
                "    try:\n",
                "        if dataset_path.endswith('.csv'):\n",
                "            dataset = load_dataset('csv', data_files=dataset_path)\n",
                "        else:\n",
                "            dataset = load_dataset(dataset_path, split='train')\n",
                "        dataset = dataset.filter(lambda x: x['text'].strip() != '' and len(x['text'].split()) > 5)\n",
                "    except Exception as e:\n",
                "        print(f'Failed to load dataset {dataset_path}: {e}')\n",
                "        dataset = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train')\n",
                "        dataset = dataset.filter(lambda x: x['text'].strip() != '' and len(x['text'].split()) > 5)\n",
                "else:\n",
                "    try:\n",
                "        dataset_files = list(input_dir.glob('*.csv'))\n",
                "        if not dataset_files:\n",
                "            raise FileNotFoundError('No CSV file found.')\n",
                "        dataset = load_dataset('csv', data_files=str(dataset_files[0]))\n",
                "    except Exception:\n",
                "        dataset = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train')\n",
                "        dataset = dataset.filter(lambda x: x['text'].strip() != '' and len(x['text'].split()) > 5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "465f2612-58e2-4dbe-96f2-667e61704f49",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Classify dataset\n",
                "num_samples = len(dataset)\n",
                "classification = 'small' if num_samples < 512 else 'big'\n",
                "data_type = 'standard NLP' if num_samples > 1000 else 'low-resource NLP'\n",
                "train_test_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
                "train_dataset = train_test_split['train']\n",
                "val_dataset = train_test_split['test']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7495f28a-6ecc-4b1d-bcb2-0b56f52c0f18",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tokenization\n",
                "base_tokenizer = AutoTokenizer.from_pretrained('GKLMIP/bert-tagalog-base-uncased')\n",
                "improved_model_path = 'distilbert-base-uncased' if classification == 'small' else 'jcblaise/roberta-tagalog-base'\n",
                "improved_tokenizer = AutoTokenizer.from_pretrained(improved_model_path, do_lower_case=False)\n",
                "\n",
                "def tokenize(examples, tokenizer):\n",
                "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
                "\n",
                "tokenized_train_base = train_dataset.map(lambda x: tokenize(x, base_tokenizer), batched=True, remove_columns=['text'])\n",
                "tokenized_val_base = val_dataset.map(lambda x: tokenize(x, base_tokenizer), batched=True, remove_columns=['text'])\n",
                "tokenized_train_improved = train_dataset.map(lambda x: tokenize(x, improved_tokenizer), batched=True, remove_columns=['text'])\n",
                "tokenized_val_improved = val_dataset.map(lambda x: tokenize(x, improved_tokenizer), batched=True, remove_columns=['text'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "406eac71-6d4f-4626-895e-22585d744426",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load models\n",
                "base_model = BertForMaskedLM.from_pretrained('GKLMIP/bert-tagalog-base-uncased').to(device)\n",
                "improved_model = RobertaForMaskedLM.from_pretrained(improved_model_path).to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5f1554f0-0a72-46e2-ae73-abb0d2109d8c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fine-tuning (skip if model already fine-tuned)\n",
                "fine_tuned_model_path = './fine_tuned_model'\n",
                "if os.path.exists(fine_tuned_model_path):\n",
                "    print(f'Loading fine-tuned model from {fine_tuned_model_path}')\n",
                "    if classification == 'small':\n",
                "        from transformers import DistilBertForMaskedLM\n",
                "        improved_model = DistilBertForMaskedLM.from_pretrained(fine_tuned_model_path).to(device)\n",
                "    else:\n",
                "        improved_model = RobertaForMaskedLM.from_pretrained(fine_tuned_model_path).to(device)\n",
                "else:\n",
                "    print('Fine-tuning model...')\n",
                "    training_args = TrainingArguments(\n",
                "        output_dir='./output',\n",
                "        num_train_epochs=1,\n",
                "        per_device_train_batch_size=4,\n",
                "        eval_strategy='no',\n",
                "        logging_dir='./logs',\n",
                "        report_to='none'\n",
                "    )\n",
                "    if classification == 'big':\n",
                "        trainer = Trainer(\n",
                "            model=improved_model,\n",
                "            args=training_args,\n",
                "            train_dataset=tokenized_train_improved,\n",
                "            eval_dataset=tokenized_val_improved,\n",
                "            data_collator=DataCollatorForLanguageModeling(tokenizer=improved_tokenizer, mlm=True)\n",
                "        )\n",
                "        trainer.train()\n",
                "        print(f'Saving fine-tuned model to {fine_tuned_model_path}')\n",
                "        improved_model.save_pretrained(fine_tuned_model_path)\n",
                "    else:\n",
                "        print('Dataset is small, skipping fine-tuning')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bb3f7485-9195-4b45-8e11-97d6c1083dd9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluation function\n",
                "def evaluate_mlm(model, tokenizer, dataset, device):\n",
                "    model.eval()\n",
                "    metric = evaluate.load('accuracy')\n",
                "    predictions, labels = [], []\n",
                "    for i in range(len(dataset)):\n",
                "        input_ids = torch.tensor(dataset[i]['input_ids']).unsqueeze(0).to(device)\n",
                "        attention_mask = torch.tensor(dataset[i]['attention_mask']).unsqueeze(0).to(device)\n",
                "        mask_token_index = (input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
                "        if len(mask_token_index) == 0:\n",
                "            valid_indices = (input_ids[0] != tokenizer.pad_token_id) & \\\n",
                "                            (input_ids[0] != tokenizer.cls_token_id) & \\\n",
                "                            (input_ids[0] != tokenizer.sep_token_id)\n",
                "            valid_indices = valid_indices.nonzero(as_tuple=True)[0]\n",
                "            if len(valid_indices) == 0:\n",
                "                continue\n",
                "            mask_idx = valid_indices[torch.randint(0, len(valid_indices), (1,)).item()]\n",
                "            original_token = input_ids[0, mask_idx].clone()\n",
                "            input_ids[0, mask_idx] = tokenizer.mask_token_id\n",
                "            mask_token_index = torch.tensor([mask_idx]).to(device)\n",
                "            original_token = [original_token.item()]\n",
                "        else:\n",
                "            original_token = input_ids[0, mask_token_index].cpu().numpy()\n",
                "            if original_token.ndim == 0:\n",
                "                original_token = [original_token.item()]\n",
                "            else:\n",
                "                original_token = original_token.tolist()\n",
                "        with torch.no_grad():\n",
                "            outputs = model(input_ids, attention_mask=attention_mask)\n",
                "            logits = outputs.logits\n",
                "            predicted_token_id = torch.argmax(logits[0, mask_token_index], dim=-1)\n",
                "            predictions.extend(predicted_token_id.cpu().numpy().tolist())\n",
                "            labels.extend(original_token)\n",
                "    if not predictions:\n",
                "        print('No valid predictions; returning 0 accuracy')\n",
                "        return 0.0\n",
                "    return metric.compute(predictions=predictions, references=labels)['accuracy']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8def5885-32ae-4172-b5ed-155017678c95",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run evaluation\n",
                "start_time = time.time()\n",
                "base_accuracy = evaluate_mlm(base_model, base_tokenizer, tokenized_val_base, device)\n",
                "improved_accuracy = evaluate_mlm(improved_model, improved_tokenizer, tokenized_val_improved, device)\n",
                "eval_time = time.time() - start_time\n",
                "print(f'BaseBERT accuracy: {base_accuracy:.4f}')\n",
                "print(f'Improved model accuracy: {improved_accuracy:.4f}')\n",
                "print(f'Evaluation time: {eval_time:.2f} seconds')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3af68f77-9a4b-4201-9e22-cab5303a417d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save results with efficiency metrics\n",
                "results = pd.DataFrame({\n",
                "    'Model': ['BaseBERT', 'Improved'],\n",
                "    'Accuracy': [base_accuracy, improved_accuracy],\n",
                "    'EvalTimeSeconds': [eval_time / 2, eval_time / 2]\n",
                "})\n",
                "results.to_csv('results.csv', index=False)\n",
                "results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "06d43b1f-060f-4d2c-8a7f-bfd1da9f6961",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Interpret results\n",
                "threshold = 0.60\n",
                "is_good = improved_accuracy >= threshold\n",
                "interpretation = {\n",
                "    'status': 'Good' if is_good else 'Needs Improvement',\n",
                "    'reason': f'Improved model (CGABERT) accuracy ({improved_accuracy:.4f}) {'exceeds' if is_good else 'is below'} threshold ({threshold}) for effective text autocomplete.'\n",
                "}\n",
                "with open('interpretation.json', 'w') as f:\n",
                "    json.dump(interpretation, f, indent=4)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
